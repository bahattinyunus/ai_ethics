"""
AI Etik Denetim: Bias (Ã–nyargÄ±) Tespiti Ã–rneÄŸi
===============================================

Bu Ã¶rnek, bir kredi deÄŸerlendirme modelinde cinsiyet bazlÄ± bias'Ä± tespit etmeyi gÃ¶sterir.
GerÃ§ek dÃ¼nyada, bu tÃ¼r analizler AI Fairness 360, Fairlearn gibi araÃ§larla yapÄ±lÄ±r.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Ã–rnek veri oluÅŸturma (gerÃ§ek projede gerÃ§ek veri kullanÄ±lÄ±r)
np.random.seed(42)
n_samples = 1000

# SimÃ¼le edilmiÅŸ kredi baÅŸvuru verileri
data = {
    'yas': np.random.randint(18, 70, n_samples),
    'gelir': np.random.randint(10000, 100000, n_samples),
    'kredi_gecmisi': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
    'cinsiyet': np.random.choice(['E', 'K'], n_samples, p=[0.5, 0.5]),
    'egitim_seviyesi': np.random.choice(['Lise', 'Lisans', 'YÃ¼ksek'], n_samples, p=[0.4, 0.4, 0.2])
}

df = pd.DataFrame(data)

# Hedef deÄŸiÅŸken: Kredi onayÄ± (bias iÃ§eren bir model simÃ¼lasyonu)
# NOT: Bu Ã¶rnekte kasÄ±tlÄ± olarak bias ekleniyor - gerÃ§ek dÃ¼nyada bu tespit edilmeli!
def create_biased_target(row):
    """Bias iÃ§eren hedef deÄŸiÅŸken (cinsiyet bazlÄ± ayrÄ±mcÄ±lÄ±k simÃ¼lasyonu)"""
    base_score = (row['gelir'] / 1000) + (row['kredi_gecmisi'] * 50) + (row['yas'] / 10)
    if row['cinsiyet'] == 'K':  # KadÄ±nlar iÃ§in daha dÃ¼ÅŸÃ¼k skor (BIAS!)
        base_score -= 20
    return 1 if base_score > 100 else 0

df['kredi_onay'] = df.apply(create_biased_target, axis=1)

# Model eÄŸitimi iÃ§in hazÄ±rlÄ±k
X = df[['yas', 'gelir', 'kredi_gecmisi', 'egitim_seviyesi']]
X = pd.get_dummies(X)  # Kategorik deÄŸiÅŸkenleri encode et
y = df['kredi_gecmisi']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model eÄŸitimi
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Tahminler
y_pred = model.predict(X_test)

print("=" * 60)
print("AI ETÄ°K DENETÄ°M: BIAS TESPÄ°TÄ° RAPORU")
print("=" * 60)

# Genel model performansÄ±
accuracy = accuracy_score(y_test, y_pred)
print(f"\nğŸ“Š Model DoÄŸruluÄŸu: {accuracy:.2%}")

# Cinsiyet bazlÄ± analiz
test_indices = X_test.index
test_data = df.loc[test_indices].copy()
test_data['tahmin'] = y_pred

print("\n" + "=" * 60)
print("ğŸ” CÄ°NSÄ°YET BAZLI ANALÄ°Z")
print("=" * 60)

for cinsiyet in ['E', 'K']:
    subset = test_data[test_data['cinsiyet'] == cinsiyet]
    if len(subset) > 0:
        onay_orani = subset['tahmin'].mean()
        print(f"\n{cinsiyet} BaÅŸvurular:")
        print(f"  - Toplam BaÅŸvuru: {len(subset)}")
        print(f"  - Onay OranÄ±: {onay_orani:.2%}")
        print(f"  - Ortalama Gelir: {subset['gelir'].mean():.0f} TL")

# Bias tespiti
erkek_onay = test_data[test_data['cinsiyet'] == 'E']['tahmin'].mean()
kadin_onay = test_data[test_data['cinsiyet'] == 'K']['tahmin'].mean()

if abs(erkek_onay - kadin_onay) > 0.1:  # %10'dan fazla fark
    print("\n" + "âš ï¸" * 30)
    print("ğŸš¨ BIAS TESPÄ°T EDÄ°LDÄ°!")
    print("âš ï¸" * 30)
    print(f"\nErkek ve KadÄ±n baÅŸvurular arasÄ±nda {abs(erkek_onay - kadin_onay):.2%} fark var.")
    print("Bu, modelin cinsiyet bazlÄ± ayrÄ±mcÄ±lÄ±k yaptÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.")
    print("\nÃ–neriler:")
    print("  1. Model eÄŸitiminde cinsiyet deÄŸiÅŸkenini kaldÄ±rÄ±n")
    print("  2. Veri setindeki cinsiyet daÄŸÄ±lÄ±mÄ±nÄ± kontrol edin")
    print("  3. IBM AI Fairness 360 veya Fairlearn kullanarak detaylÄ± analiz yapÄ±n")
    print("  4. Modeli yeniden eÄŸitin ve bias'Ä± azaltÄ±n")
else:
    print("\nâœ… Cinsiyet bazlÄ± Ã¶nemli bir bias tespit edilmedi.")

print("\n" + "=" * 60)
print("ğŸ“ ETÄ°K DENETÄ°M NOTLARI")
print("=" * 60)
print("""
Bu Ã¶rnek, AI modellerinde bias tespitinin Ã¶nemini gÃ¶sterir.
GerÃ§ek dÃ¼nyada:
- IBM AI Fairness 360 kullanarak 20+ farklÄ± adalet metriÄŸi hesaplayÄ±n
- FarklÄ± demografik gruplar iÃ§in model performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±n
- GDPR ve AI Act gerekliliklerine uygunluk kontrolÃ¼ yapÄ±n
- ÅeffaflÄ±k raporu hazÄ±rlayÄ±n
""")

