# ğŸ§ª AI Etik Denetim Pratik Ã–rnekleri

Bu klasÃ¶r, AI etik denetimi iÃ§in pratik kod Ã¶rnekleri iÃ§erir.

## ğŸ“ Dosyalar

### 1. `bias_detection_example.py`
**Bias (Ã–nyargÄ±) Tespiti Ã–rneÄŸi**

Bir kredi deÄŸerlendirme modelinde cinsiyet bazlÄ± bias'Ä± nasÄ±l tespit edeceÄŸinizi gÃ¶sterir.

**KullanÄ±m:**
```bash
python bias_detection_example.py
```

**Ã–ÄŸrenecekleriniz:**
- Model bias'Ä±nÄ± nasÄ±l tespit edersiniz
- Demografik gruplar arasÄ± performans farklarÄ±nÄ± nasÄ±l analiz edersiniz
- Bias tespit edildiÄŸinde ne yapmalÄ±sÄ±nÄ±z

---

### 2. `model_explainability_example.py`
**Model AÃ§Ä±klanabilirliÄŸi Ã–rneÄŸi**

SHAP kullanarak model kararlarÄ±nÄ± nasÄ±l aÃ§Ä±klayabileceÄŸinizi gÃ¶sterir.

**KullanÄ±m:**
```bash
# SHAP ile (Ã¶nerilir)
pip install shap
python model_explainability_example.py

# SHAP olmadan (basit versiyon)
python model_explainability_example.py
```

**Ã–ÄŸrenecekleriniz:**
- Model kararlarÄ±nÄ± nasÄ±l aÃ§Ä±klarsÄ±nÄ±z
- GDPR "Right to Explanation" gerekliliÄŸini nasÄ±l karÅŸÄ±larsÄ±nÄ±z
- SHAP deÄŸerlerini nasÄ±l yorumlarsÄ±nÄ±z

---

### 3. `ethics_checklist.py`
**Etik Denetim Checklist Script'i**

AI projeleriniz iÃ§in etik denetim checklist'i oluÅŸturmanÄ±zÄ± saÄŸlar.

**KullanÄ±m:**
```bash
python ethics_checklist.py
```

**Ã–zellikler:**
- KapsamlÄ± etik denetim checklist'i
- Otomatik rapor oluÅŸturma
- JSON formatÄ±nda kayÄ±t
- Risk takibi

**Checklist Kategorileri:**
- âœ… Veri EtiÄŸi
- âœ… Model EtiÄŸi
- âœ… Uyumluluk (GDPR, KVKK, AI Act)
- âœ… Risk YÃ¶netimi
- âœ… ÅeffaflÄ±k

---

## ğŸš€ Kurulum

1. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
```

2. Ã–rnekleri Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
python bias_detection_example.py
python model_explainability_example.py
python ethics_checklist.py
```

## ğŸ“š Ã–nerilen AraÃ§lar

Bu Ã¶rnekler temel seviyededir. GerÃ§ek projelerde ÅŸu araÃ§larÄ± kullanmanÄ±z Ã¶nerilir:

- **IBM AI Fairness 360** - KapsamlÄ± bias tespiti
- **Fairlearn** - Microsoft'un adil ML aracÄ±
- **SHAP** - Model aÃ§Ä±klanabilirliÄŸi
- **LIME** - Yerel model aÃ§Ä±klanabilirliÄŸi
- **What-If Tool** - Google'Ä±n model analiz aracÄ±

## ğŸ”— Ä°lgili Kaynaklar

- [IBM AI Fairness 360](https://github.com/Trusted-AI/AIF360)
- [Fairlearn](https://fairlearn.org/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [EU AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)

## âš ï¸ Not

Bu Ã¶rnekler eÄŸitim amaÃ§lÄ±dÄ±r. GerÃ§ek projelerde:
- GerÃ§ek veri setleri kullanÄ±n
- Daha kapsamlÄ± bias analizi yapÄ±n
- Yasal danÄ±ÅŸmanlÄ±k alÄ±n
- DetaylÄ± dokÃ¼mantasyon hazÄ±rlayÄ±n

