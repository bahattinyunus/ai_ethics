"""
AI Etik Denetim: Model AÃ§Ä±klanabilirliÄŸi (Explainability) Ã–rneÄŸi
=================================================================

Bu Ã¶rnek, SHAP (SHapley Additive exPlanations) kullanarak
bir modelin kararlarÄ±nÄ± nasÄ±l aÃ§Ä±klayabileceÄŸimizi gÃ¶sterir.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# SHAP kÃ¼tÃ¼phanesi yoksa basit bir alternatif gÃ¶sterelim
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("âš ï¸ SHAP kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. Basit aÃ§Ä±klanabilirlik Ã¶rneÄŸi gÃ¶sterilecek.")
    print("   YÃ¼klemek iÃ§in: pip install shap\n")

# Ã–rnek veri: Ä°ÅŸe alÄ±m kararÄ±
np.random.seed(42)
n_samples = 500

data = {
    'deneyim_yili': np.random.randint(0, 15, n_samples),
    'egitim_seviyesi': np.random.choice([1, 2, 3], n_samples, p=[0.3, 0.5, 0.2]),  # 1:Lise, 2:Lisans, 3:YÃ¼ksek
    'teknik_test_skoru': np.random.randint(50, 100, n_samples),
    'mÃ¼lakat_skoru': np.random.randint(40, 95, n_samples),
    'referans_sayisi': np.random.randint(0, 5, n_samples)
}

df = pd.DataFrame(data)

# Ä°ÅŸe alÄ±m kararÄ± (basit bir kural)
def ise_alim_karari(row):
    score = (row['deneyim_yili'] * 5 + 
             row['egitim_seviyesi'] * 10 + 
             row['teknik_test_skoru'] * 0.5 + 
             row['mÃ¼lakat_skoru'] * 0.4 + 
             row['referans_sayisi'] * 5)
    return 1 if score > 150 else 0

df['ise_alindi'] = df.apply(ise_alim_karari, axis=1)

# Model eÄŸitimi
X = df.drop('ise_alindi', axis=1)
y = df['ise_alindi']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("=" * 70)
print("AI ETÄ°K DENETÄ°M: MODEL AÃ‡IKLANABÄ°LÄ°RLÄ°ÄÄ° RAPORU")
print("=" * 70)

# Feature importance (basit aÃ§Ä±klanabilirlik)
feature_importance = pd.DataFrame({
    'Ã¶zellik': X.columns,
    'Ã¶nem': model.feature_importances_
}).sort_values('Ã¶nem', ascending=False)

print("\nğŸ“Š Ã–zellik Ã–nem SÄ±ralamasÄ±:")
print("-" * 70)
for idx, row in feature_importance.iterrows():
    print(f"  {row['Ã¶zellik']:25s}: {row['Ã¶nem']:.3f} ({row['Ã¶nem']*100:.1f}%)")

# SHAP kullanarak detaylÄ± aÃ§Ä±klama
if SHAP_AVAILABLE:
    print("\n" + "=" * 70)
    print("ğŸ” SHAP Analizi (DetaylÄ± AÃ§Ä±klanabilirlik)")
    print("=" * 70)
    
    # SHAP explainer oluÅŸtur
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_test[:10])  # Ä°lk 10 Ã¶rnek iÃ§in
    
    print("\nSHAP deÄŸerleri hesaplandÄ±. Bu deÄŸerler her Ã¶zelliÄŸin")
    print("her tahmin iÃ§in ne kadar katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir.")
    print("\nÃ–rnek tahmin aÃ§Ä±klamasÄ± (ilk baÅŸvuru):")
    print("-" * 70)
    
    # Ä°lk Ã¶rnek iÃ§in aÃ§Ä±klama
    sample_idx = 0
    sample = X_test.iloc[sample_idx]
    prediction = model.predict([sample])[0]
    
    print(f"\nBaÅŸvuru #{sample_idx + 1}:")
    print(f"  Tahmin: {'Ä°ÅŸe AlÄ±ndÄ± âœ…' if prediction == 1 else 'Ä°ÅŸe AlÄ±nmadÄ± âŒ'}")
    print(f"  OlasÄ±lÄ±k: {model.predict_proba([sample])[0][1]:.2%}")
    print(f"\n  Ã–zellik DeÄŸerleri:")
    for feature in X.columns:
        print(f"    {feature:25s}: {sample[feature]}")
    
    print(f"\n  SHAP KatkÄ±larÄ± (pozitif = iÅŸe alÄ±mÄ± artÄ±rÄ±r, negatif = azaltÄ±r):")
    if isinstance(shap_values, list):
        shap_vals = shap_values[1][sample_idx]  # Pozitif sÄ±nÄ±f iÃ§in
    else:
        shap_vals = shap_values[sample_idx]
    
    for i, feature in enumerate(X.columns):
        contribution = shap_vals[i]
        direction = "â†‘" if contribution > 0 else "â†“"
        print(f"    {feature:25s}: {contribution:+.3f} {direction}")
    
    print("\nğŸ’¡ Bu aÃ§Ä±klamalar, modelin kararlarÄ±nÄ±n ÅŸeffaf olmasÄ±nÄ± saÄŸlar.")
    print("   GDPR ve AI Act, kullanÄ±cÄ±larÄ±n AI kararlarÄ±nÄ± anlama hakkÄ±nÄ± garanti eder.")
else:
    print("\n" + "=" * 70)
    print("ğŸ’¡ GeliÅŸmiÅŸ AÃ§Ä±klanabilirlik iÃ§in SHAP KullanÄ±mÄ±")
    print("=" * 70)
    print("""
SHAP (SHapley Additive exPlanations) kullanarak:
1. Her Ã¶zelliÄŸin her tahmin iÃ§in katkÄ±sÄ±nÄ± gÃ¶rebilirsiniz
2. Model kararlarÄ±nÄ± bireysel seviyede aÃ§Ä±klayabilirsiniz
3. GDPR ve AI Act gerekliliklerine uygun ÅŸeffaflÄ±k saÄŸlayabilirsiniz

Kurulum:
  pip install shap

KullanÄ±m Ã¶rneÄŸi:
  import shap
  explainer = shap.TreeExplainer(model)
  shap_values = explainer.shap_values(X_test)
  shap.summary_plot(shap_values, X_test)
""")

print("\n" + "=" * 70)
print("ğŸ“‹ ETÄ°K DENETÄ°M KONTROL LÄ°STESÄ°")
print("=" * 70)
print("""
âœ… Model kararlarÄ± aÃ§Ä±klanabilir mi?
âœ… KullanÄ±cÄ±lar neden reddedildiklerini/onaylandÄ±klarÄ±nÄ± anlayabiliyor mu?
âœ… GDPR 'Right to Explanation' gerekliliÄŸi karÅŸÄ±lanÄ±yor mu?
âœ… AI Act ÅŸeffaflÄ±k gereklilikleri saÄŸlanÄ±yor mu?
âœ… Model dokÃ¼mantasyonu mevcut mu?
""")

